{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наши данные на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
    "                                                    df['cardio'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К полям:\n",
    "- gender, cholesterol применим OHE-кодирование\n",
    "- age, height, weight, ap_hi, ap_lo - standardScaler\n",
    "- gluc, smoke, alco, active - оставим пока как есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь объединим все наши трансформеры с помощью FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим классификатор и запустим кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_show(y_true, y_pred):\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_color_codes(\"muted\")\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    fpr, tpr, thresholds_ = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve ')\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 4s, sys: 5.71 s, total: 5min 9s\n",
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>TNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.730323</td>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.837558</td>\n",
       "      <td>0.784035</td>\n",
       "      <td>4861</td>\n",
       "      <td>1411</td>\n",
       "      <td>7269</td>\n",
       "      <td>3959</td>\n",
       "      <td>0.837442</td>\n",
       "      <td>0.448866</td>\n",
       "      <td>0.551134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.718863</td>\n",
       "      <td>0.642669</td>\n",
       "      <td>0.815553</td>\n",
       "      <td>0.771037</td>\n",
       "      <td>4991</td>\n",
       "      <td>1663</td>\n",
       "      <td>7017</td>\n",
       "      <td>3829</td>\n",
       "      <td>0.808410</td>\n",
       "      <td>0.434127</td>\n",
       "      <td>0.565873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.737766</td>\n",
       "      <td>0.692471</td>\n",
       "      <td>0.789401</td>\n",
       "      <td>0.794572</td>\n",
       "      <td>5777</td>\n",
       "      <td>1829</td>\n",
       "      <td>6851</td>\n",
       "      <td>3043</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.345011</td>\n",
       "      <td>0.654989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n",
       "      <td>0.739621</td>\n",
       "      <td>0.689686</td>\n",
       "      <td>0.797350</td>\n",
       "      <td>0.801092</td>\n",
       "      <td>5706</td>\n",
       "      <td>1760</td>\n",
       "      <td>6920</td>\n",
       "      <td>3114</td>\n",
       "      <td>0.797235</td>\n",
       "      <td>0.353061</td>\n",
       "      <td>0.646939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model    fscore  precision  \\\n",
       "0                                 LogisticRegression  0.730323   0.647431   \n",
       "1                             RandomForestClassifier  0.718863   0.642669   \n",
       "2                                 AdaBoostClassifier  0.737766   0.692471   \n",
       "3  <catboost.core.CatBoostClassifier object at 0x...  0.739621   0.689686   \n",
       "\n",
       "     recall   roc_auc    TN    FN    TP    FP       TPR       FPR       TNR  \n",
       "0  0.837558  0.784035  4861  1411  7269  3959  0.837442  0.448866  0.551134  \n",
       "1  0.815553  0.771037  4991  1663  7017  3829  0.808410  0.434127  0.565873  \n",
       "2  0.789401  0.794572  5777  1829  6851  3043  0.789286  0.345011  0.654989  \n",
       "3  0.797350  0.801092  5706  1760  6920  3114  0.797235  0.353061  0.646939  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = [LogisticRegression(random_state=42), \n",
    "          RandomForestClassifier(random_state=42),\n",
    "          AdaBoostClassifier(random_state=42),\n",
    "          CatBoostClassifier(random_state=42, silent=True)]\n",
    "\n",
    "def evaluate_model(model):\n",
    "    classifier = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('classifier', model),\n",
    "    ])\n",
    "\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_score = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    b=1\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "    fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "    ix = np.argmax(fscore)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true=y_test, y_score=classifier.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_score>thresholds[ix])\n",
    "    \n",
    "    TN = cnf_matrix[0][0]\n",
    "    FN = cnf_matrix[1][0]\n",
    "    TP = cnf_matrix[1][1]\n",
    "    FP = cnf_matrix[0][1]\n",
    "    \n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "    TNR = TN/(FP+TN)\n",
    "    TPR, FPR, TNR\n",
    "    \n",
    "    return fscore[ix], precision[ix], recall[ix], roc_auc, TN, FN, TP, FP, TPR, FPR, TNR\n",
    "\n",
    "evaluation_scores = pd.DataFrame(columns=['model', \n",
    "                                          'fscore', \n",
    "                                          'precision', \n",
    "                                          'recall', \n",
    "                                          'roc_auc', \n",
    "                                          'TN',\n",
    "                                          'FN',\n",
    "                                          'TP',\n",
    "                                          'FP',\n",
    "                                          'TPR',\n",
    "                                          'FPR',\n",
    "                                          'TNR'])\n",
    "\n",
    "for model in models:\n",
    "    fscore, precision, recall, roc_auc, TN, FN, TP, FP, TPR, FPR, TNR = evaluate_model(model)\n",
    "    to_append = {'model': str(model).split(\"(\")[0], \n",
    "                 'fscore': fscore, \n",
    "                 'precision': precision, \n",
    "                 'recall': recall, \n",
    "                 'roc_auc': roc_auc, 'TN': TN, 'FN': FN, 'TP': TP, 'FP': FP, 'TPR': TPR, 'FPR': FPR, 'TNR': TNR}\n",
    "    evaluation_scores = evaluation_scores.append(to_append, ignore_index=True)\n",
    "    \n",
    "evaluation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Если судить строго по f-score, не вдаваясь в смысл задачи, то, конечно, catboost побеждает как лучшая модель с данным показателем. Однако, в задачах, где цена ошибки за предсказание False Negative (второго рода) велика, то я бы оринетировался на наивысший показатель recall. В этой задаче среди всех моделей наилучший показатель FN, и recall - у LogisticRegression. Иными словами, FN - значит ложноотрицательно заключение, модель посчитала человека здоровым, а у него было сердечно-сосудистое заболевание. У LogisticRegression этот показатель наименьший. Все, конечно же, зависит от поставленной задачи, имеющихся средств и бюджета, и желаемого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опциональный вопрос (задание 5): Конечно же для несбалансированных датасетов лучше подходит precision_recall_curve, precision и recall специально предназначены для обнаружения редких событий и весьма полезны в таких сценариях, где датасет имбалансен. precision и recall покажут, что наш классификатор плохо справляется, если он неправильно классифицирует большую часть или весь класс меньшинства."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
